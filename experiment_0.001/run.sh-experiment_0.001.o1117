/var/lib/gridengine
Mon Jun 25 14:38:40 2018       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 384.130                Driver Version: 384.130                   |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 1080    Off  | 00000000:01:00.0 Off |                  N/A |
| 38%   56C    P2    40W / 180W |   1789MiB /  8114MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0     21236      C   .../jose/torch_im76_dec/install/bin/luajit  1779MiB |
+-----------------------------------------------------------------------------+
2018-06-25 14:39:20.956044: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-06-25 14:39:21.029142: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-06-25 14:39:21.029530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 6.07GiB
2018-06-25 14:39:21.029541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0
2018-06-25 14:39:50.086472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-06-25 14:39:50.107591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 
2018-06-25 14:39:50.107602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N 
2018-06-25 14:39:50.107750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5848 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)
2018-06-25 14:39:54.408395: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.80GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
Train model
-----------------------------------------------------------------
Train Data: (914, 288, 384, 3)
-----------------------------------------------------------------
Epoch 1/15
Epoch 2/15
Epoch 3/15
Epoch 4/15
Epoch 5/15
Epoch 6/15
Epoch 7/15
Epoch 8/15
Epoch 9/15
Epoch 10/15
Epoch 11/15
Epoch 12/15
Epoch 13/15
Epoch 14/15
Epoch 15/15
Decode model
-----------------------------------------------------------------
Traceback (most recent call last):
  File "/scratch/projekt1/AdvertisementDetection/runAdvertisementDetection.py", line 99, in <module>
    runner.start()
  File "/scratch/projekt1/AdvertisementDetection/runAdvertisementDetection.py", line 37, in start
    recogSystem.evaluateModel()
  File "/scratch/projekt1/AdvertisementDetection/src/advertisementDetection.py", line 81, in evaluateModel
    self.predictData(x,y)
  File "/scratch/projekt1/AdvertisementDetection/src/advertisementDetection.py", line 88, in predictData
    predictions = self.model.predict(X)
NameError: name 'X' is not defined
